{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b68255d2",
   "metadata": {},
   "source": [
    "Megan Sisson\n",
    "DSC 680 Applied Data Science\n",
    "Project 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a847cbb1",
   "metadata": {},
   "source": [
    "Customer Review using Vader to understand the sentiment of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874eda29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mksis\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import collections\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mksis/Documents/Data Science/680 Applied DS/Reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bebb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8015274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d67136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing row for null value from reviewerName\n",
    "df[df['reviewerName'].isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe7bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping reviews by reviewTime to see the frequency of reviews each day.\n",
    "df['reviewTime'] = pd.to_datetime(df['reviewTime'])\n",
    "df_group = df.groupby('reviewTime').count()\n",
    "\n",
    "df_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80461a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of reviews by time\n",
    "df_group.plot(y = 'reviewerID', use_index = True, ylabel = 'Count', title = 'Count of Reviews Over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Review rating [overall]\n",
    "rating = df['overall'].value_counts()\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf1e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph for Ratings\n",
    "rating.plot.bar(title = 'Rating Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d010bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert reviewText2 to string\n",
    "df['reviewText'] = df['reviewText'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b94cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the reviewText\n",
    "#lowercase text\n",
    "df['reviewText2'] = df['reviewText'].str.lower()\n",
    "#remove punctuation\n",
    "df['reviewText2'] = df['reviewText2'].str.replace('[^\\w\\s]', '')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81878d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment analyzer. Adding polarity columns\n",
    "df['polarity'] = df['reviewText2'].apply(lambda x: sia.polarity_scores(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e87712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform polarity column into columns for negative, neutral, positive, and compound\n",
    "\n",
    "df[['neg', 'neu', 'pos', 'compound']] = df['polarity'].apply(pd.Series)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8918dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize compound score compared to review score\n",
    "ax = sb.barplot(data = df, x = 'overall', y = 'compound')\n",
    "ax.set_title('Compound Score by Amazon Overall Score')\n",
    "plt.show()\n",
    "#This plot makes sense, as the compound score is low, it should also correlate to a low overall score\n",
    "# and a higher compound score should correlate to a higher overall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize overall score to the negative, neutral, and positive scores\n",
    "fig, axs = plt.subplots(1, 3, figsize = (15, 5))\n",
    "sb.barplot(data = df, x = 'overall', y = 'pos', ax=axs[0])\n",
    "sb.barplot(data = df, x = 'overall', y = 'neu', ax=axs[1])\n",
    "sb.barplot(data = df, x = 'overall', y = 'neg', ax=axs[2])\n",
    "axs[0].set_title('Positive')\n",
    "axs[1].set_title('Neutral')\n",
    "axs[2].set_title('Negative')\n",
    "#Confirms what we hope to see\n",
    "#Positive polarity increases as overall score increases\n",
    "#Negative polarity increases as overall score increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd1b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot to see relationship between overall score and compound score\n",
    "df.plot.scatter(x = 'overall', y = 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns not needed for model\n",
    "df2 = df.drop(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText', 'summary', 'unixReviewTime', 'reviewTime', 'day_diff',\n",
    "       'helpful_yes', 'total_vote', 'reviewText2', 'polarity'], axis = 1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting 'overall' to string\n",
    "df2['overall'] = df2['overall'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de62073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into X(independent) and y(dependent)\n",
    "X = df2.drop('overall', axis = 1)\n",
    "y = df2.overall\n",
    "print(\"X shape: \", X.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 42)\n",
    "print('Training shape: ', X_train.shape)\n",
    "print('Testing shape: ', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model Random Forest Classification\n",
    "classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0242f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph Actual vs Predicted\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual overall score')\n",
    "plt.ylabel('Predicted overall score')\n",
    "plt.title('Actual vs Predicted overall score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy Score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy score: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix Heatmap\n",
    "sb.heatmap(cm, annot = True, fmt = 'd', xticklabels = ['1', '2', '3', '4', '5'], \n",
    "           yticklabels = ['1', '2', '3', '4', '5'], cmap = plt.cm.Greens)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
